# üéôÔ∏è Guia Completo: Sistema Automatizado de Podcast

## üìã Vis√£o Geral da Solu√ß√£o

Este sistema resolve **TODOS** os problemas mencionados e cria um pipeline 100% automatizado de gera√ß√£o de roteiros de podcast.

---

## üéØ Problemas Resolvidos

|#|Problema Original|Solu√ß√£o Implementada|
|---|---|---|
|1|**Emails repetidos**|‚úÖ Deduplica√ß√£o autom√°tica por hash de conte√∫do + URL|
|2|**Extra√ß√µes incompletas**|‚úÖ Sistema de qualidade m√≠nima + retry inteligente|
|3|**Sites com paywall**|‚úÖ Estrat√©gias m√∫ltiplas de extra√ß√£o + log de tentativas|
|4|**Sele√ß√£o manual**|‚úÖ Classifica√ß√£o AI autom√°tica com score composto|
|5|**Gerar relat√≥rio**|‚úÖ LLM gera roteiro completo em markdown|
|6|**Automa√ß√£o completa**|‚úÖ Cron job √†s 9h UTC gera podcast automaticamente|
|7|**Exportar para NotebookLM**|‚úÖ Roteiro em markdown pronto para upload|

---

## üîÑ Fluxo Automatizado Completo

```
08:00 UTC ‚Üí Sync Gmail (Google Alerts)
    ‚Üì
08:00-08:30 ‚Üí Extra√ß√£o de conte√∫do
    ‚Üì
08:30-08:45 ‚Üí Classifica√ß√£o AI
    ‚Üì
    ‚îú‚îÄ‚Üí Duplicata? ‚Üí Marca e descarta
    ‚îú‚îÄ‚Üí Baixa qualidade? ‚Üí Agenda retry
    ‚îî‚îÄ‚Üí Boa qualidade? ‚Üí Segue para podcast
    ‚Üì
09:00 UTC ‚Üí GERA√á√ÉO AUTOM√ÅTICA DE PODCAST
    ‚Üì
    ‚îú‚îÄ‚Üí Seleciona 3-10 melhores artigos
    ‚îú‚îÄ‚Üí Calcula score composto:
    ‚îÇ   ‚Ä¢ Confidence Score (40%)
    ‚îÇ   ‚Ä¢ Word Count (30%)
    ‚îÇ   ‚Ä¢ Quality Score (30%)
    ‚îú‚îÄ‚Üí Envia para LLM
    ‚îú‚îÄ‚Üí Gera roteiro profissional
    ‚îî‚îÄ‚Üí Salva em podcast_episodes
    ‚Üì
09:15 UTC ‚Üí Roteiro pronto para uso
    ‚Üì
MANUAL ‚Üí Download markdown
    ‚Üì
MANUAL ‚Üí Upload para NotebookLM
    ‚Üì
MANUAL ‚Üí Gerar √°udio
```

---

## üóÑÔ∏è Novas Tabelas Criadas

### 1. **podcast_episodes**

Armazena roteiros gerados diariamente.

```sql
-- Campos principais:
- script_markdown (TEXT) ‚Üí Roteiro completo em markdown
- article_ids (UUID[]) ‚Üí IDs dos artigos inclu√≠dos
- estimated_duration_minutes (INT) ‚Üí Dura√ß√£o estimada
- quality_score (NUMERIC) ‚Üí Score de qualidade (0-1)
- notebooklm_url (TEXT) ‚Üí URL do podcast gerado
```

**Constraint:** Um epis√≥dio por usu√°rio por dia

---

### 2. **content_deduplication_log**

Rastreia e previne duplicatas.

```sql
-- Como funciona:
1. Calcula hash do t√≠tulo + URL + conte√∫do
2. Verifica se j√° existe nos √∫ltimos 30 dias
3. Se duplicata ‚Üí marca alert como 'duplicate'
4. Alert duplicado N√ÉO √© processado
```

---

### 3. **extraction_strategies_log**

Monitora qualidade de extra√ß√µes.

```sql
-- Avalia qualidade:
- excellent: 300+ palavras
- good: 150+ palavras
- partial: 50+ palavras
- failed: < 50 palavras

-- Se failed/partial ‚Üí agenda retry autom√°tico
```

---

## ü§ñ Como Funciona a Gera√ß√£o de Podcast

### **Etapa 1: Sele√ß√£o Inteligente de Artigos**

```sql
-- Score composto:
final_score = 
  confidence_score * 0.4 +     -- Relev√¢ncia da IA
  (word_count / 1000) * 0.3 +  -- Tamanho do conte√∫do
  quality_score * 0.3          -- Qualidade da extra√ß√£o

-- Seleciona top 3-10 artigos
```

### **Etapa 2: Prepara√ß√£o do Contexto**

```json
{
  "date": "2026-01-26",
  "articles": [
    {
      "title": "Nova IA revoluciona...",
      "publisher": "TechCrunch",
      "content": "Texto completo...",
      "category": "IA",
      "reasoning": "Por que √© relevante"
    }
  ],
  "target_duration_minutes": 15
}
```

### **Etapa 3: Gera√ß√£o com LLM**

**Prompt otimizado:**

```
Voc√™ √© roteirista de podcast especializado em tech/IA.

REGRAS:
- Tom conversacional (amigos conversando)
- Introdu√ß√£o cativante
- Transi√ß√µes suaves
- Analogias e exemplos
- Destaque implica√ß√µes pr√°ticas
- Conex√µes entre artigos
- Dura√ß√£o: 15 minutos

ESTRUTURA:
- Abertura (30s)
- Intro ao tema (1min)
- 3-5 blocos principais (80%)
- Encerramento (1min)

FORMATO MARKDOWN:
- Headers (##, ###)
- [PAUSA] onde apropriado
- [√äNFASE] em pontos importantes
- [TRANSI√á√ÉO] entre blocos
```

**Providers em cascata:**

1. OpenRouter (Gemini 2.0 Flash - **gratuito**)
2. OpenAI (GPT-4o-mini)
3. Gemini Direct
4. Fallback: roteiro b√°sico

### **Etapa 4: Resultado Final**

```markdown
## Tecnologia em Foco - 26 de Janeiro de 2026

Ol√°! Bem-vindo ao seu resumo di√°rio de tecnologia e IA.

[PAUSA]

Hoje temos novidades [√äNFASE] revolucion√°rias [/√äNFASE] sobre...

### Primeira Not√≠cia: IA Generativa Atinge Novo Marco

A empresa X lan√ßou...

[TRANSI√á√ÉO]

### Segunda Not√≠cia: Avan√ßo em Computa√ß√£o Qu√¢ntica

Pesquisadores conseguiram...

---

## Encerramento

Essas foram as principais not√≠cias de hoje!
O que voc√™ acha dessas inova√ß√µes?

üéß At√© amanh√£!
```

---

## ‚öôÔ∏è Configura√ß√£o e Deploy

### **Passo 1: Executar Scripts SQL**

```bash
# No Supabase SQL Editor:
1. Execute todo o script do artefato "SQL: Sistema de Podcast Autom√°tico"
2. Aguarde confirma√ß√£o de sucesso
3. Verifique tabelas criadas
```

### **Passo 2: Deploy da Edge Function**

```bash
# Criar fun√ß√£o
mkdir -p supabase/functions/generate-podcast-script
cd supabase/functions/generate-podcast-script

# Copiar c√≥digo do artefato "Edge Function: Generate Podcast Script"
nano index.ts
# Cole o c√≥digo e salve (Ctrl+X, Y, Enter)

# Deploy
supabase functions deploy generate-podcast-script

# Verificar
supabase functions list
```

### **Passo 3: Configurar Vari√°veis de Ambiente**

```bash
# No Supabase Dashboard:
# Settings ‚Üí Edge Functions ‚Üí Environment variables

OPENROUTER_API_KEY=sk-or-v1-...
OPENAI_API_KEY=sk-proj-...
GEMINI_API_KEY=AIza...
```

### **Passo 4: Testar Manualmente**

```sql
-- Gerar podcast para hoje
SELECT public.generate_daily_podcast_script(
  CURRENT_DATE,  -- data
  auth.uid(),    -- usu√°rio
  3,             -- m√≠nimo de artigos
  10             -- m√°ximo de artigos
);

-- Ver resultado
SELECT * FROM podcast_episodes 
WHERE episode_date = CURRENT_DATE
ORDER BY created_at DESC
LIMIT 1;
```

### **Passo 5: Ativar Automa√ß√£o**

```sql
-- Verificar cron job
SELECT * FROM cron.job 
WHERE jobname = 'auto-generate-daily-podcasts';

-- Status esperado:
-- jobname: auto-generate-daily-podcasts
-- schedule: 0 9 * * * (9h UTC diariamente)
-- active: true
```

---

## üìä Monitoramento e Uso

### **Dashboard de M√©tricas**

```sql
-- 1. Estat√≠sticas di√°rias
SELECT * FROM podcast_daily_stats;

-- Resultado:
-- episode_date | episodes | articles | avg_quality | avg_duration
-- 2026-01-26   | 1        | 7        | 0.92        | 14.5

-- 2. Artigos prontos para pr√≥ximo podcast
SELECT * FROM podcast_ready_articles 
WHERE NOT used_in_podcast 
LIMIT 10;

-- 3. Duplicatas detectadas esta semana
SELECT * FROM duplicate_alerts_summary;

-- 4. Extra√ß√µes com problemas
SELECT * FROM problematic_extractions;
```

### **Acessar Roteiro Gerado**

```sql
-- Buscar epis√≥dio de hoje
SELECT 
  title,
  description,
  script_markdown,
  total_articles,
  estimated_duration_minutes
FROM podcast_episodes
WHERE episode_date = CURRENT_DATE
  AND user_id = auth.uid();

-- Copiar script_markdown e salvar como .md
```

---

## üéØ Workflow Di√°rio Automatizado

### **08:00 UTC - Sincroniza√ß√£o**

```
‚úÖ Cron job: trigger-gmail-sync
   ‚Üì
‚úÖ Busca emails com label "Alertas"
   ‚Üì
‚úÖ Extrai artigos do HTML
   ‚Üì
‚úÖ Insere em alerts (status: pending)
   ‚Üì
‚úÖ Trigger autom√°tico: extract-content
```

### **08:00-08:30 - Extra√ß√£o**

```
‚úÖ Jina Reader extrai conte√∫do
   ‚Üì
‚úÖ Cheerio como fallback
   ‚Üì
‚úÖ Traduz para PT-BR (opcional)
   ‚Üì
‚úÖ Calcula quality_score
   ‚Üì
‚úÖ Se < 100 palavras ‚Üí agenda retry
```

### **08:30-08:45 - Classifica√ß√£o**

```
‚úÖ OpenRouter/OpenAI classifica
   ‚Üì
‚úÖ Retorna: linkedin/archive + confidence
   ‚Üì
‚úÖ Se confidence > 0.8 ‚Üí auto-aprova
   ‚Üì
‚úÖ Marca artigo como pronto
```

### **09:00 UTC - Gera√ß√£o de Podcast**

```
‚úÖ Cron job: auto-generate-daily-podcasts
   ‚Üì
‚úÖ Para cada usu√°rio ativo:
   ‚îú‚îÄ Busca artigos de hoje
   ‚îú‚îÄ Filtra duplicatas
   ‚îú‚îÄ Calcula scores
   ‚îú‚îÄ Seleciona top 3-10
   ‚îú‚îÄ Envia para LLM
   ‚îî‚îÄ Salva em podcast_episodes
```

### **09:15 UTC - Pronto para Uso**

```
‚úÖ Roteiro em markdown dispon√≠vel
   ‚Üì
MANUAL: Download do roteiro
   ‚Üì
MANUAL: Upload para NotebookLM
   ‚Üì
MANUAL: Gerar √°udio
   ‚Üì
‚úÖ Podcast pronto!
```

---

## üöÄ Recursos Avan√ßados

### **1. Retry Inteligente de Extra√ß√µes**

```sql
-- Reprocessar extra√ß√µes ruins
SELECT * FROM public.retry_poor_extractions(5);

-- Retorna:
-- alert_id | retry_result | new_word_count
-- uuid-1   | SUCCESS      | 523
-- uuid-2   | FAILED       | 0
```

### **2. Gerar Podcast de Outra Data**

```sql
-- Gerar podcast de ontem
SELECT public.generate_daily_podcast_script(
  CURRENT_DATE - INTERVAL '1 day'
);

-- Gerar podcast customizado
SELECT public.generate_daily_podcast_script(
  '2026-01-25'::date,  -- data espec√≠fica
  auth.uid(),          -- usu√°rio
  5,                   -- m√≠n 5 artigos
  15                   -- m√°x 15 artigos
);
```

### **3. Atualizar Roteiro Existente**

```sql
-- Se quiser regenerar
DELETE FROM podcast_episodes 
WHERE episode_date = CURRENT_DATE;

-- Gerar novamente
SELECT public.generate_daily_podcast_script(CURRENT_DATE);
```

---

## üì§ Exportar para NotebookLM

### **M√©todo 1: Manual (Recomendado)**

```bash
# 1. Buscar roteiro no banco
SELECT script_markdown FROM podcast_episodes 
WHERE episode_date = CURRENT_DATE;

# 2. Copiar conte√∫do
# 3. Salvar como: podcast_2026-01-26.md
# 4. Acessar: https://notebooklm.google.com
# 5. New Notebook ‚Üí Upload ‚Üí Selecionar .md
# 6. Generate Audio Overview
# 7. Download MP3
```

### **M√©todo 2: API (Futuro - quando NotebookLM tiver API)**

```typescript
// Quando API estiver dispon√≠vel:
async function uploadToNotebookLM(scriptMarkdown: string) {
  const response = await fetch('https://notebooklm.google.com/api/v1/upload', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer ' + NOTEBOOKLM_API_KEY,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      content: scriptMarkdown,
      format: 'markdown',
      auto_generate_audio: true
    })
  })
  
  return await response.json()
}
```

---

## üîß Troubleshooting

### **Problema: Nenhum podcast gerado**

```sql
-- Verificar artigos dispon√≠veis
SELECT COUNT(*) FROM podcast_ready_articles 
WHERE NOT used_in_podcast;

-- Se COUNT < 3 ‚Üí N√£o tem artigos suficientes
-- Solu√ß√£o: Aguardar mais artigos ou diminuir m√≠nimo
SELECT public.generate_daily_podcast_script(
  CURRENT_DATE,
  auth.uid(),
  1,  -- aceita 1 artigo apenas
  10
);
```

### **Problema: Qualidade baixa do roteiro**

```sql
-- Ver score do epis√≥dio
SELECT quality_score FROM podcast_episodes 
WHERE episode_date = CURRENT_DATE;

-- Se < 0.7 ‚Üí Regenerar com mais artigos
DELETE FROM podcast_episodes WHERE episode_date = CURRENT_DATE;

SELECT public.generate_daily_podcast_script(
  CURRENT_DATE,
  auth.uid(),
  5,   -- aumentar m√≠nimo
  15   -- aumentar m√°ximo
);
```

### **Problema: Muitas duplicatas**

```sql
-- Ver duplicatas de hoje
SELECT COUNT(*) FROM alerts 
WHERE created_at::date = CURRENT_DATE
  AND status = 'duplicate';

-- Se > 50% ‚Üí Revisar fontes RSS/Gmail
-- Poss√≠vel causa: mesmo artigo vindo de m√∫ltiplas fontes
```

### **Problema: Extra√ß√µes falhando**

```sql
-- Ver extra√ß√µes problem√°ticas
SELECT * FROM problematic_extractions;

-- Tentar retry
SELECT * FROM public.retry_poor_extractions(10);

-- Se continuar falhando ‚Üí Site pode ter paywall
-- Criar estrat√©gia manual ou usar fonte alternativa
```

---

## üìà M√©tricas de Sucesso

Ap√≥s implementa√ß√£o, voc√™ deve ter:

|M√©trica|Objetivo|Como Medir|
|---|---|---|
|**Podcasts gerados/dia**|1 por usu√°rio|`SELECT COUNT(*) FROM podcast_episodes WHERE episode_date = CURRENT_DATE`|
|**Taxa de deduplica√ß√£o**|< 20% duplicatas|`SELECT * FROM duplicate_alerts_summary`|
|**Qualidade m√©dia**|> 0.8|`SELECT AVG(quality_score) FROM podcast_episodes`|
|**Artigos por epis√≥dio**|5-8|`SELECT AVG(total_articles) FROM podcast_episodes`|
|**Tempo de processamento**|< 60 minutos|Monitorar logs de 8h-9h|

---

## üéÅ Benef√≠cios da Solu√ß√£o

‚úÖ **100% Automatizado** - Zero interven√ß√£o manual at√© o roteiro  
‚úÖ **Inteligente** - Seleciona apenas o melhor conte√∫do  
‚úÖ **Eficiente** - Elimina duplicatas automaticamente  
‚úÖ **Robusto** - Retry autom√°tico em falhas  
‚úÖ **Escal√°vel** - Funciona para m√∫ltiplos usu√°rios  
‚úÖ **Profissional** - Roteiros otimizados para podcast  
‚úÖ **Flex√≠vel** - Compat√≠vel com NotebookLM e outras ferramentas

---

## üîÆ Pr√≥ximas Evolu√ß√µes Poss√≠veis

### **Fase 2: Automa√ß√£o Total**

- Integra√ß√£o direta com NotebookLM API (quando dispon√≠vel)
- Gera√ß√£o de √°udio autom√°tica
- Publica√ß√£o em Spotify/Apple Podcasts

### **Fase 3: Personaliza√ß√£o**

- M√∫ltiplos formatos (tech, business, geral)
- Dura√ß√£o customiz√°vel por usu√°rio
- Tom de voz personalizado

### **Fase 4: An√°lise Avan√ßada**

- Detec√ß√£o de trending topics
- Agrupamento por tema
- Sugest√£o de s√©ries de epis√≥dios

---

## üìö Recursos e Refer√™ncias

- [NotebookLM](https://notebooklm.google.com/) - Gera√ß√£o de √°udio
- [Supabase Cron](https://supabase.com/docs/guides/database/extensions/pg_cron) - Agendamento
- [OpenRouter](https://openrouter.ai/) - API de LLMs gratuitos
- [Jina Reader](https://jina.ai/reader) - Extra√ß√£o de conte√∫do

---

**√öltima Atualiza√ß√£o:** Janeiro 2026  
**Vers√£o:** 1.0  
**Status:** ‚úÖ Pronto para produ√ß√£o



// ============================================================================
// EDGE FUNCTION: generate-podcast-script
// Gera roteiro de podcast em markdown usando LLM
// Caminho: supabase/functions/generate-podcast-script/index.ts
// ============================================================================

import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

// Tipos
interface Article {
  id: string
  title: string
  publisher: string
  url: string
  content: string
  category?: string
  reasoning?: string
}

interface PodcastRequest {
  date: string
  articles: Article[]
  total_articles: number
  target_duration_minutes: number
  format: string
}

interface PodcastScript {
  title: string
  description: string
  script_markdown: string
  metadata: {
    estimated_duration: number
    quality_score: number
    sections: string[]
    topics_covered: string[]
  }
}

// Configura√ß√£o
const OPENROUTER_API_KEY = Deno.env.get('OPENROUTER_API_KEY')
const OPENAI_API_KEY = Deno.env.get('OPENAI_API_KEY')
const GEMINI_API_KEY = Deno.env.get('GEMINI_API_KEY')

// ============================================================================
// FUN√á√ÉO PRINCIPAL
// ============================================================================

serve(async (req) => {
  try {
    // Verificar autentica√ß√£o
    const authHeader = req.headers.get('Authorization')
    if (!authHeader) {
      return new Response(
        JSON.stringify({ error: 'Missing authorization header' }),
        { status: 401, headers: { 'Content-Type': 'application/json' } }
      )
    }

    // Parse request
    const payload: PodcastRequest = await req.json()
    
    console.log(`Generating podcast script for ${payload.date} with ${payload.total_articles} articles`)

    // Validar payload
    if (!payload.articles || payload.articles.length === 0) {
      return new Response(
        JSON.stringify({ error: 'No articles provided' }),
        { status: 400, headers: { 'Content-Type': 'application/json' } }
      )
    }

    // Gerar roteiro usando IA
    const script = await generatePodcastScript(payload)

    // Retornar resultado
    return new Response(
      JSON.stringify(script),
      { 
        status: 200, 
        headers: { 'Content-Type': 'application/json' }
      }
    )

  } catch (error) {
    console.error('Error generating podcast script:', error)
    
    return new Response(
      JSON.stringify({ 
        error: error.message || 'Internal server error',
        details: error.toString()
      }),
      { 
        status: 500, 
        headers: { 'Content-Type': 'application/json' } 
      }
    )
  }
})

// ============================================================================
// GERA√á√ÉO DE ROTEIRO COM IA
// ============================================================================

async function generatePodcastScript(payload: PodcastRequest): Promise<PodcastScript> {
  // Preparar contexto dos artigos
  const articlesContext = payload.articles
    .map((article, index) => {
      return `
### Artigo ${index + 1}: ${article.title}
**Fonte:** ${article.publisher}
**URL:** ${article.url}
**Categoria:** ${article.category || 'N√£o classificado'}

**Conte√∫do:**
${article.content.substring(0, 1500)}...

${article.reasoning ? `**Por que √© relevante:** ${article.reasoning}` : ''}
---
`
    })
    .join('\n')

  // Criar prompt otimizado para podcast
  const systemPrompt = `Voc√™ √© um roteirista especializado em podcasts de tecnologia e IA.
Seu objetivo √© criar roteiros envolventes, conversacionais e informativos.

REGRAS PARA O ROTEIRO:
1. Tom conversacional e natural (como se fosse uma conversa entre amigos)
2. Introdu√ß√£o cativante que desperte curiosidade
3. Transi√ß√µes suaves entre t√≥picos
4. Contextualize cada not√≠cia antes de entrar nos detalhes
5. Use analogias e exemplos quando apropriado
6. Destaque implica√ß√µes pr√°ticas e impacto real
7. Fa√ßa conex√µes entre diferentes artigos quando relevante
8. Termine com reflex√£o ou call-to-action
9. Dura√ß√£o estimada: ${payload.target_duration_minutes} minutos

ESTRUTURA OBRIGAT√ìRIA:
- Abertura (30 segundos)
- Introdu√ß√£o ao tema do dia (1 minuto)
- Desenvolvimento: 3-5 blocos principais (80% do tempo)
- Encerramento e reflex√£o final (1 minuto)

FORMATO:
- Use markdown com headers (##, ###)
- Inclua [PAUSA] onde apropriado
- Marque [√äNFASE] em pontos importantes
- Adicione [TRANSI√á√ÉO] entre blocos`

  const userPrompt = `Data do epis√≥dio: ${payload.date}
Total de artigos selecionados: ${payload.total_articles}

${articlesContext}

TAREFA:
Crie um roteiro de podcast profissional e envolvente sobre esses artigos.
O roteiro deve:
1. Sintetizar as principais not√≠cias do dia
2. Conectar os t√≥picos de forma l√≥gica
3. Destacar insights e implica√ß√µes
4. Ser f√°cil de narrar (conversacional)
5. Durar aproximadamente ${payload.target_duration_minutes} minutos quando lido

Retorne APENAS um JSON v√°lido com esta estrutura:
{
  "title": "T√≠tulo atrativo do epis√≥dio",
  "description": "Breve descri√ß√£o (2-3 frases)",
  "script_markdown": "Roteiro completo em markdown",
  "metadata": {
    "estimated_duration": ${payload.target_duration_minutes},
    "quality_score": 0.95,
    "sections": ["Abertura", "T√≥pico 1", "T√≥pico 2", "Encerramento"],
    "topics_covered": ["IA", "Tecnologia", "Inova√ß√£o"]
  }
}`

  // Tentar providers em ordem (OpenRouter -> OpenAI -> Gemini)
  let response: PodcastScript | null = null

  // 1. Tentar OpenRouter (Gemini 2.0 Flash - gratuito)
  if (OPENROUTER_API_KEY && !response) {
    try {
      console.log('Trying OpenRouter (Gemini 2.0 Flash)...')
      response = await callOpenRouter(systemPrompt, userPrompt)
    } catch (error) {
      console.error('OpenRouter failed:', error.message)
    }
  }

  // 2. Tentar OpenAI
  if (OPENAI_API_KEY && !response) {
    try {
      console.log('Trying OpenAI (GPT-4o-mini)...')
      response = await callOpenAI(systemPrompt, userPrompt)
    } catch (error) {
      console.error('OpenAI failed:', error.message)
    }
  }

  // 3. Tentar Gemini Direct
  if (GEMINI_API_KEY && !response) {
    try {
      console.log('Trying Gemini Direct...')
      response = await callGemini(systemPrompt, userPrompt)
    } catch (error) {
      console.error('Gemini failed:', error.message)
    }
  }

  // Se tudo falhar, gerar roteiro b√°sico
  if (!response) {
    console.warn('All AI providers failed, generating basic script...')
    response = generateBasicScript(payload)
  }

  return response
}

// ============================================================================
// CHAMADAS PARA PROVIDERS DE IA
// ============================================================================

async function callOpenRouter(systemPrompt: string, userPrompt: string): Promise<PodcastScript> {
  const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
      'Content-Type': 'application/json',
      'HTTP-Referer': 'https://meu-painel.app',
      'X-Title': 'Meu Painel - Podcast Generator'
    },
    body: JSON.stringify({
      model: 'google/gemini-2.0-flash-exp:free',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      response_format: { type: 'json_object' },
      temperature: 0.7,
      max_tokens: 4000
    })
  })

  if (!response.ok) {
    throw new Error(`OpenRouter API error: ${response.status}`)
  }

  const data = await response.json()
  const content = data.choices[0].message.content
  
  return parseAIResponse(content)
}

async function callOpenAI(systemPrompt: string, userPrompt: string): Promise<PodcastScript> {
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${OPENAI_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      response_format: { type: 'json_object' },
      temperature: 0.7,
      max_tokens: 4000
    })
  })

  if (!response.ok) {
    throw new Error(`OpenAI API error: ${response.status}`)
  }

  const data = await response.json()
  const content = data.choices[0].message.content
  
  return parseAIResponse(content)
}

async function callGemini(systemPrompt: string, userPrompt: string): Promise<PodcastScript> {
  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${GEMINI_API_KEY}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents: [{
          parts: [{
            text: `${systemPrompt}\n\n${userPrompt}`
          }]
        }],
        generationConfig: {
          temperature: 0.7,
          maxOutputTokens: 4000,
          responseMimeType: 'application/json'
        }
      })
    }
  )

  if (!response.ok) {
    throw new Error(`Gemini API error: ${response.status}`)
  }

  const data = await response.json()
  const content = data.candidates[0].content.parts[0].text
  
  return parseAIResponse(content)
}

// ============================================================================
// PARSING E FALLBACK
// ============================================================================

function parseAIResponse(content: string): PodcastScript {
  try {
    // Remover markdown code blocks se presentes
    const cleanContent = content
      .replace(/```json\n?/g, '')
      .replace(/```\n?/g, '')
      .trim()
    
    const parsed = JSON.parse(cleanContent)
    
    // Validar estrutura
    if (!parsed.title || !parsed.script_markdown) {
      throw new Error('Invalid response structure')
    }
    
    return {
      title: parsed.title,
      description: parsed.description || '',
      script_markdown: parsed.script_markdown,
      metadata: {
        estimated_duration: parsed.metadata?.estimated_duration || 15,
        quality_score: parsed.metadata?.quality_score || 0.8,
        sections: parsed.metadata?.sections || [],
        topics_covered: parsed.metadata?.topics_covered || []
      }
    }
  } catch (error) {
    console.error('Failed to parse AI response:', error)
    throw new Error('Invalid JSON response from AI')
  }
}

function generateBasicScript(payload: PodcastRequest): PodcastScript {
  // Gerar roteiro b√°sico sem IA
  const date = new Date(payload.date).toLocaleDateString('pt-BR', {
    weekday: 'long',
    year: 'numeric',
    month: 'long',
    day: 'numeric'
  })

  const articlesText = payload.articles
    .map((article, i) => `
### ${i + 1}. ${article.title}

**Fonte:** ${article.publisher}

${article.content.substring(0, 500)}...

üîó [Leia mais](${article.url})
`)
    .join('\n---\n')

  const script = `
## Resumo de Not√≠cias - ${date}

Ol√°! Bem-vindo ao resumo di√°rio de tecnologia e inova√ß√£o.

Hoje temos ${payload.total_articles} artigos selecionados especialmente para voc√™.

---

${articlesText}

---

## Encerramento

Essas foram as principais not√≠cias de hoje. Fique ligado para mais atualiza√ß√µes!

üéß Obrigado por nos ouvir!
`

  return {
    title: `Resumo de Tecnologia - ${date}`,
    description: `Resumo das principais not√≠cias de tecnologia e IA do dia ${payload.date}`,
    script_markdown: script,
    metadata: {
      estimated_duration: payload.target_duration_minutes,
      quality_score: 0.5,
      sections: ['Abertura', 'Not√≠cias', 'Encerramento'],
      topics_covered: payload.articles.map(a => a.category || 'Tech').filter(Boolean)
    }
  }
}

// ============================================================================
// EXEMPLO DE USO
// ============================================================================

/*
POST https://seu-projeto.supabase.co/functions/v1/generate-podcast-script
Authorization: Bearer <service_role_key>
Content-Type: application/json

{
  "date": "2026-01-26",
  "articles": [
    {
      "id": "uuid-1",
      "title": "Nova IA revoluciona ind√∫stria",
      "publisher": "TechNews",
      "url": "https://example.com/article1",
      "content": "Conte√∫do completo do artigo...",
      "category": "IA",
      "reasoning": "Inova√ß√£o disruptiva no setor"
    }
  ],
  "total_articles": 1,
  "target_duration_minutes": 15,
  "format": "conversational_podcast"
}

RESPOSTA:
{
  "title": "IA Revolucion√°ria: O Futuro Chegou",
  "description": "An√°lise das √∫ltimas inova√ß√µes em IA...",
  "script_markdown": "## Abertura\n\nOl√°! Hoje vamos...",
  "metadata": {
    "estimated_duration": 15,
    "quality_score": 0.95,
    "sections": ["Abertura", "Desenvolvimento", "Encerramento"],
    "topics_covered": ["IA", "Inova√ß√£o"]
  }
}
*/

-- ============================================================================
-- SISTEMA AUTOM√ÅTICO DE GERA√á√ÉO DE ROTEIROS DE PODCAST
-- Integrado ao pipeline existente de curadoria de conte√∫do
-- ============================================================================

-- ----------------------------------------------------------------------------
-- PARTE 1: NOVAS TABELAS PARA SISTEMA DE PODCAST
-- ----------------------------------------------------------------------------

-- 1.1: Tabela para armazenar roteiros de podcast gerados
CREATE TABLE IF NOT EXISTS public.podcast_episodes (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  
  -- Metadados do epis√≥dio
  episode_date DATE NOT NULL DEFAULT CURRENT_DATE,
  title TEXT NOT NULL,
  description TEXT,
  
  -- Conte√∫do do roteiro
  script_markdown TEXT NOT NULL, -- Roteiro completo em markdown
  script_metadata JSONB DEFAULT '{}'::jsonb, -- Se√ß√µes, dura√ß√£o estimada, etc
  
  -- Artigos inclu√≠dos
  article_ids UUID[] NOT NULL, -- Array de IDs dos alerts inclu√≠dos
  total_articles INTEGER NOT NULL DEFAULT 0,
  
  -- Status e qualidade
  status TEXT NOT NULL DEFAULT 'draft' CHECK (status IN ('draft', 'ready', 'published')),
  quality_score NUMERIC(3,2) CHECK (quality_score >= 0 AND quality_score <= 1),
  
  -- Estat√≠sticas
  estimated_duration_minutes INTEGER, -- Dura√ß√£o estimada em minutos
  word_count INTEGER,
  
  -- Integra√ß√£o NotebookLM
  notebooklm_url TEXT, -- URL do podcast gerado (se exportado)
  audio_generated BOOLEAN DEFAULT false,
  
  -- Timestamps
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  published_at TIMESTAMPTZ,
  
  -- Constraints
  CONSTRAINT unique_episode_per_day UNIQUE (user_id, episode_date)
);

-- √çndices para performance
CREATE INDEX idx_podcast_episodes_user_date ON public.podcast_episodes(user_id, episode_date DESC);
CREATE INDEX idx_podcast_episodes_status ON public.podcast_episodes(status) WHERE status = 'draft';

-- RLS
ALTER TABLE public.podcast_episodes ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own podcast episodes"
ON public.podcast_episodes FOR SELECT
USING (auth.uid() = user_id);

CREATE POLICY "Users can insert own podcast episodes"
ON public.podcast_episodes FOR INSERT
WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can update own podcast episodes"
ON public.podcast_episodes FOR UPDATE
USING (auth.uid() = user_id);

COMMENT ON TABLE public.podcast_episodes IS 
'Armazena roteiros de podcast gerados automaticamente a partir dos artigos do dia';

-- 1.2: Tabela para logs de deduplica√ß√£o
CREATE TABLE IF NOT EXISTS public.content_deduplication_log (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  alert_id UUID REFERENCES public.alerts(id) ON DELETE CASCADE,
  
  -- Hash para detectar duplicatas
  content_hash TEXT NOT NULL,
  url_hash TEXT NOT NULL,
  
  -- Informa√ß√µes de duplicata
  is_duplicate BOOLEAN DEFAULT false,
  original_alert_id UUID REFERENCES public.alerts(id),
  
  -- Timestamps
  checked_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  
  CONSTRAINT unique_content_hash UNIQUE (content_hash)
);

CREATE INDEX idx_dedup_content_hash ON public.content_deduplication_log(content_hash);
CREATE INDEX idx_dedup_url_hash ON public.content_deduplication_log(url_hash);

-- 1.3: Tabela para estrat√©gias de extra√ß√£o avan√ßada
CREATE TABLE IF NOT EXISTS public.extraction_strategies_log (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  alert_id UUID REFERENCES public.alerts(id) ON DELETE CASCADE,
  
  -- Estrat√©gias tentadas
  strategies_tried JSONB NOT NULL DEFAULT '[]'::jsonb, -- Array de {strategy, success, timestamp}
  successful_strategy TEXT,
  
  -- Resultado
  extraction_quality TEXT CHECK (extraction_quality IN ('excellent', 'good', 'partial', 'failed')),
  paywall_detected BOOLEAN DEFAULT false,
  
  -- Dados para retry
  retry_count INTEGER DEFAULT 0,
  last_retry_at TIMESTAMPTZ,
  should_retry BOOLEAN DEFAULT false,
  
  -- Timestamps
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_extraction_strategies_alert ON public.extraction_strategies_log(alert_id);
CREATE INDEX idx_extraction_strategies_retry ON public.extraction_strategies_log(should_retry) 
WHERE should_retry = true;

-- ----------------------------------------------------------------------------
-- PARTE 2: FUN√á√ïES AUXILIARES DE DEDUPLICA√á√ÉO
-- ----------------------------------------------------------------------------

-- 2.1: Fun√ß√£o para calcular hash de conte√∫do
CREATE OR REPLACE FUNCTION public.calculate_content_hash(
  title TEXT,
  url TEXT,
  content TEXT DEFAULT NULL
)
RETURNS TEXT
LANGUAGE plpgsql
IMMUTABLE
AS $$
BEGIN
  -- Gera hash MD5 da combina√ß√£o normalizada
  RETURN md5(
    LOWER(TRIM(title)) || '||' || 
    REGEXP_REPLACE(LOWER(url), 'https?://(www\.)?', '') || '||' ||
    COALESCE(LEFT(LOWER(content), 500), '')
  );
END;
$$;

-- 2.2: Fun√ß√£o para detectar e marcar duplicatas
CREATE OR REPLACE FUNCTION public.mark_duplicate_alerts()
RETURNS TRIGGER
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  content_hash_value TEXT;
  url_hash_value TEXT;
  existing_alert_id UUID;
BEGIN
  -- Calcular hashes
  content_hash_value := public.calculate_content_hash(NEW.title, NEW.clean_url);
  url_hash_value := md5(LOWER(REGEXP_REPLACE(NEW.clean_url, 'https?://(www\.)?', '')));
  
  -- Verificar se j√° existe alerta similar nos √∫ltimos 30 dias
  SELECT id INTO existing_alert_id
  FROM public.alerts
  WHERE id != NEW.id
    AND created_at > NOW() - INTERVAL '30 days'
    AND (
      md5(LOWER(TRIM(title)) || '||' || REGEXP_REPLACE(LOWER(clean_url), 'https?://(www\.)?', '')) = content_hash_value
      OR md5(LOWER(REGEXP_REPLACE(clean_url, 'https?://(www\.)?', ''))) = url_hash_value
    )
  LIMIT 1;
  
  -- Registrar no log de deduplica√ß√£o
  INSERT INTO public.content_deduplication_log (
    alert_id,
    content_hash,
    url_hash,
    is_duplicate,
    original_alert_id
  ) VALUES (
    NEW.id,
    content_hash_value,
    url_hash_value,
    existing_alert_id IS NOT NULL,
    existing_alert_id
  )
  ON CONFLICT (content_hash) DO NOTHING;
  
  -- Se for duplicata, marcar status e n√£o processar
  IF existing_alert_id IS NOT NULL THEN
    NEW.status := 'duplicate';
    RAISE NOTICE 'Alert % marked as duplicate of %', NEW.id, existing_alert_id;
  END IF;
  
  RETURN NEW;
END;
$$;

-- 2.3: Criar trigger de deduplica√ß√£o
DROP TRIGGER IF EXISTS trigger_check_duplicates ON public.alerts;

CREATE TRIGGER trigger_check_duplicates
  BEFORE INSERT ON public.alerts
  FOR EACH ROW
  EXECUTE FUNCTION public.mark_duplicate_alerts();

-- Adicionar coluna status 'duplicate' se n√£o existir
DO $$
BEGIN
  ALTER TABLE public.alerts 
  DROP CONSTRAINT IF EXISTS alerts_status_check;
  
  ALTER TABLE public.alerts 
  ADD CONSTRAINT alerts_status_check 
  CHECK (status IN ('pending', 'extracted', 'classified', 'approved', 'published', 'needs_review', 'duplicate', 'archived'));
EXCEPTION
  WHEN duplicate_object THEN NULL;
END $$;

-- ----------------------------------------------------------------------------
-- PARTE 3: SISTEMA DE EXTRA√á√ÉO INTELIGENTE COM RETRY
-- ----------------------------------------------------------------------------

-- 3.1: Fun√ß√£o para avaliar qualidade da extra√ß√£o
CREATE OR REPLACE FUNCTION public.evaluate_extraction_quality(
  word_count INTEGER,
  has_meaningful_content BOOLEAN,
  extraction_method TEXT
)
RETURNS TEXT
LANGUAGE plpgsql
IMMUTABLE
AS $$
BEGIN
  IF NOT has_meaningful_content THEN
    RETURN 'failed';
  ELSIF word_count >= 300 THEN
    RETURN 'excellent';
  ELSIF word_count >= 150 THEN
    RETURN 'good';
  ELSIF word_count >= 50 THEN
    RETURN 'partial';
  ELSE
    RETURN 'failed';
  END IF;
END;
$$;

-- 3.2: Trigger para avaliar extra√ß√£o e agendar retry
CREATE OR REPLACE FUNCTION public.evaluate_and_schedule_retry()
RETURNS TRIGGER
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  quality TEXT;
  has_content BOOLEAN;
BEGIN
  -- Avaliar se tem conte√∫do significativo
  has_content := NEW.extracted_text IS NOT NULL 
                 AND LENGTH(NEW.extracted_text) > 50
                 AND NEW.extracted_text !~* '^(subscribe|sign up|login)';
  
  -- Calcular qualidade
  quality := public.evaluate_extraction_quality(
    NEW.word_count,
    has_content,
    COALESCE(NEW.extraction_status, 'unknown')
  );
  
  -- Registrar no log de estrat√©gias
  INSERT INTO public.extraction_strategies_log (
    alert_id,
    extraction_quality,
    should_retry
  ) VALUES (
    NEW.alert_id,
    quality,
    quality IN ('partial', 'failed') AND NEW.word_count < 100
  )
  ON CONFLICT (alert_id) 
  DO UPDATE SET
    extraction_quality = EXCLUDED.extraction_quality,
    should_retry = EXCLUDED.should_retry,
    updated_at = NOW();
  
  -- Se qualidade ruim, marcar alert para revis√£o
  IF quality IN ('partial', 'failed') THEN
    UPDATE public.alerts
    SET status = 'needs_review'
    WHERE id = NEW.alert_id;
  END IF;
  
  RETURN NEW;
END;
$$;

DROP TRIGGER IF EXISTS trigger_evaluate_extraction ON public.extracted_content;

CREATE TRIGGER trigger_evaluate_extraction
  AFTER INSERT OR UPDATE OF extracted_text ON public.extracted_content
  FOR EACH ROW
  EXECUTE FUNCTION public.evaluate_and_schedule_retry();

-- ----------------------------------------------------------------------------
-- PARTE 4: FUN√á√ÉO PRINCIPAL DE GERA√á√ÉO DE ROTEIRO DE PODCAST
-- ----------------------------------------------------------------------------

CREATE OR REPLACE FUNCTION public.generate_daily_podcast_script(
  target_date DATE DEFAULT CURRENT_DATE,
  target_user_id UUID DEFAULT auth.uid(),
  min_articles INTEGER DEFAULT 3,
  max_articles INTEGER DEFAULT 10
)
RETURNS UUID -- Retorna ID do epis√≥dio criado
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = public
AS $$
DECLARE
  episode_id UUID;
  selected_articles JSONB;
  script_payload JSONB;
  ai_response JSONB;
  article_count INTEGER;
BEGIN
  -- Selecionar melhores artigos do dia
  WITH ranked_articles AS (
    SELECT 
      a.id,
      a.title,
      a.publisher,
      a.clean_url,
      ec.cleaned_content,
      ec.word_count,
      ac.confidence_score,
      ac.reasoning,
      ac.category,
      -- Score composto
      (
        COALESCE(ac.confidence_score, 0) * 0.4 +
        LEAST(ec.word_count / 1000.0, 1.0) * 0.3 +
        CASE WHEN ec.quality_score > 0.7 THEN 0.3 ELSE 0 END
      ) as final_score
    FROM public.alerts a
    INNER JOIN public.extracted_content ec ON ec.alert_id = a.id
    LEFT JOIN public.ai_classifications ac ON ac.alert_id = a.id
    WHERE a.created_at::date = target_date
      AND a.user_id = target_user_id
      AND a.status NOT IN ('duplicate', 'archived')
      AND ec.word_count >= 100 -- Conte√∫do m√≠nimo
      AND (ac.destination = 'linkedin' OR ac.destination IS NULL)
    ORDER BY final_score DESC
    LIMIT max_articles
  )
  SELECT 
    jsonb_agg(
      jsonb_build_object(
        'id', id,
        'title', title,
        'publisher', publisher,
        'url', clean_url,
        'content', cleaned_content,
        'category', category,
        'reasoning', reasoning
      )
      ORDER BY final_score DESC
    ),
    COUNT(*)
  INTO selected_articles, article_count
  FROM ranked_articles;
  
  -- Verificar se tem artigos suficientes
  IF article_count < min_articles THEN
    RAISE EXCEPTION 'Insufficient articles: found %, minimum required %', 
      article_count, min_articles;
  END IF;
  
  -- Preparar payload para IA
  script_payload := jsonb_build_object(
    'date', target_date,
    'articles', selected_articles,
    'total_articles', article_count,
    'target_duration_minutes', 15,
    'format', 'conversational_podcast'
  );
  
  -- Chamar Edge Function para gerar roteiro
  BEGIN
    ai_response := public.invoke_edge_function(
      'generate-podcast-script',
      script_payload
    );
  EXCEPTION WHEN OTHERS THEN
    RAISE WARNING 'Failed to generate podcast script: %', SQLERRM;
    RETURN NULL;
  END;
  
  -- Criar epis√≥dio no banco
  INSERT INTO public.podcast_episodes (
    user_id,
    episode_date,
    title,
    description,
    script_markdown,
    script_metadata,
    article_ids,
    total_articles,
    word_count,
    estimated_duration_minutes,
    quality_score,
    status
  )
  SELECT
    target_user_id,
    target_date,
    COALESCE(ai_response->>'title', 'Resumo Di√°rio - ' || target_date::text),
    ai_response->>'description',
    ai_response->>'script_markdown',
    ai_response->'metadata',
    ARRAY(SELECT jsonb_array_elements_text(selected_articles->'id')),
    article_count,
    LENGTH(ai_response->>'script_markdown') / 5, -- Estimativa de palavras
    (ai_response->'metadata'->>'estimated_duration')::integer,
    (ai_response->'metadata'->>'quality_score')::numeric,
    'ready'
  RETURNING id INTO episode_id;
  
  RAISE NOTICE 'Podcast episode % created with % articles', episode_id, article_count;
  
  RETURN episode_id;
END;
$$;

COMMENT ON FUNCTION public.generate_daily_podcast_script IS
'Gera automaticamente roteiro de podcast a partir dos melhores artigos do dia';

-- ----------------------------------------------------------------------------
-- PARTE 5: CRON JOB PARA GERA√á√ÉO AUTOM√ÅTICA DE PODCAST
-- ----------------------------------------------------------------------------

-- 5.1: Criar fun√ß√£o wrapper para cron job
CREATE OR REPLACE FUNCTION public.auto_generate_daily_podcasts()
RETURNS void
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  user_record RECORD;
  episode_id UUID;
BEGIN
  -- Para cada usu√°rio ativo
  FOR user_record IN
    SELECT DISTINCT user_id
    FROM public.email_accounts
    WHERE oauth_connected = true
      AND sync_enabled = true
  LOOP
    BEGIN
      -- Gerar podcast para o usu√°rio
      episode_id := public.generate_daily_podcast_script(
        CURRENT_DATE,
        user_record.user_id,
        3, -- min 3 artigos
        10 -- max 10 artigos
      );
      
      RAISE NOTICE 'Generated podcast % for user %', episode_id, user_record.user_id;
      
    EXCEPTION WHEN OTHERS THEN
      RAISE WARNING 'Failed to generate podcast for user %: %', 
        user_record.user_id, SQLERRM;
    END;
  END LOOP;
END;
$$;

-- 5.2: Agendar gera√ß√£o di√°ria √†s 9h UTC (ap√≥s sync das 8h)
SELECT cron.unschedule('auto-generate-daily-podcasts');

SELECT cron.schedule(
  'auto-generate-daily-podcasts',
  '0 9 * * *', -- 9h UTC diariamente (1h ap√≥s sync)
  $$SELECT public.auto_generate_daily_podcasts()$$
);

COMMENT ON FUNCTION public.auto_generate_daily_podcasts IS
'Cron job que gera podcasts di√°rios para todos os usu√°rios ativos';

-- ----------------------------------------------------------------------------
-- PARTE 6: VIEWS PARA MONITORAMENTO
-- ----------------------------------------------------------------------------

-- 6.1: View de estat√≠sticas di√°rias de podcast
CREATE OR REPLACE VIEW public.podcast_daily_stats AS
SELECT 
  episode_date,
  COUNT(DISTINCT id) as episodes_generated,
  SUM(total_articles) as total_articles_used,
  AVG(quality_score) as avg_quality_score,
  AVG(estimated_duration_minutes) as avg_duration,
  COUNT(*) FILTER (WHERE status = 'published') as published_count
FROM public.podcast_episodes
WHERE episode_date >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY episode_date
ORDER BY episode_date DESC;

-- 6.2: View de artigos prontos para podcast
CREATE OR REPLACE VIEW public.podcast_ready_articles AS
SELECT 
  a.id,
  a.title,
  a.publisher,
  a.clean_url,
  a.created_at::date as article_date,
  ec.word_count,
  ec.quality_score as extraction_quality,
  ac.confidence_score,
  ac.category,
  -- Score composto
  (
    COALESCE(ac.confidence_score, 0) * 0.4 +
    LEAST(ec.word_count / 1000.0, 1.0) * 0.3 +
    CASE WHEN ec.quality_score > 0.7 THEN 0.3 ELSE 0 END
  ) as podcast_score,
  -- J√° usado em podcast?
  EXISTS (
    SELECT 1 FROM public.podcast_episodes pe
    WHERE a.id = ANY(pe.article_ids)
  ) as used_in_podcast
FROM public.alerts a
INNER JOIN public.extracted_content ec ON ec.alert_id = a.id
LEFT JOIN public.ai_classifications ac ON ac.alert_id = a.id
WHERE a.status NOT IN ('duplicate', 'archived')
  AND ec.word_count >= 100
  AND a.created_at >= CURRENT_DATE - INTERVAL '7 days'
ORDER BY podcast_score DESC;

-- ----------------------------------------------------------------------------
-- PARTE 7: FUN√á√ÉO DE RETRY INTELIGENTE PARA EXTRA√á√ïES RUINS
-- ----------------------------------------------------------------------------

CREATE OR REPLACE FUNCTION public.retry_poor_extractions(
  limit_count INTEGER DEFAULT 5
)
RETURNS TABLE(
  alert_id UUID,
  retry_result TEXT,
  new_word_count INTEGER
)
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  alert_rec RECORD;
  response JSONB;
BEGIN
  -- Buscar extra√ß√µes que devem ser retentadas
  FOR alert_rec IN
    SELECT 
      a.id,
      a.clean_url,
      a.title,
      esl.retry_count
    FROM public.alerts a
    INNER JOIN public.extraction_strategies_log esl ON esl.alert_id = a.id
    LEFT JOIN public.extracted_content ec ON ec.alert_id = a.id
    WHERE esl.should_retry = true
      AND esl.retry_count < 3
      AND a.status IN ('pending', 'needs_review')
    ORDER BY a.created_at DESC
    LIMIT limit_count
  LOOP
    BEGIN
      -- Tentar reextrair com estrat√©gia avan√ßada
      response := public.invoke_edge_function(
        'extract-content-advanced',
        jsonb_build_object(
          'alert_id', alert_rec.id,
          'url', alert_rec.clean_url,
          'title', alert_rec.title,
          'use_advanced_strategies', true,
          'retry_attempt', alert_rec.retry_count + 1
        )
      );
      
      -- Atualizar log
      UPDATE public.extraction_strategies_log
      SET 
        retry_count = retry_count + 1,
        last_retry_at = NOW(),
        should_retry = false
      WHERE alert_id = alert_rec.id;
      
      RETURN QUERY SELECT 
        alert_rec.id, 
        'SUCCESS'::text,
        (response->>'word_count')::integer;
      
    EXCEPTION WHEN OTHERS THEN
      RETURN QUERY SELECT 
        alert_rec.id, 
        ('FAILED: ' || SQLERRM)::text,
        0;
    END;
  END LOOP;
END;
$$;

-- ----------------------------------------------------------------------------
-- PARTE 8: QUERIES √öTEIS PARA MONITORAMENTO
-- ----------------------------------------------------------------------------

-- 8.1: Ver epis√≥dios de podcast gerados
COMMENT ON VIEW public.podcast_daily_stats IS
'SELECT * FROM public.podcast_daily_stats LIMIT 7;';

-- 8.2: Ver artigos prontos para pr√≥ximo podcast
COMMENT ON VIEW public.podcast_ready_articles IS
'SELECT * FROM public.podcast_ready_articles WHERE NOT used_in_podcast LIMIT 10;';

-- 8.3: Gerar podcast manualmente
COMMENT ON FUNCTION public.generate_daily_podcast_script IS
'SELECT public.generate_daily_podcast_script(CURRENT_DATE, auth.uid(), 3, 10);';

-- 8.4: Ver duplicatas detectadas
CREATE OR REPLACE VIEW public.duplicate_alerts_summary AS
SELECT 
  DATE(checked_at) as detection_date,
  COUNT(*) as total_duplicates,
  COUNT(DISTINCT original_alert_id) as unique_originals
FROM public.content_deduplication_log
WHERE is_duplicate = true
  AND checked_at >= CURRENT_DATE - INTERVAL '7 days'
GROUP BY DATE(checked_at)
ORDER BY detection_date DESC;

-- 8.5: Ver extra√ß√µes com problemas
CREATE OR REPLACE VIEW public.problematic_extractions AS
SELECT 
  a.id,
  a.title,
  a.clean_url,
  esl.extraction_quality,
  esl.retry_count,
  esl.paywall_detected,
  ec.word_count
FROM public.alerts a
INNER JOIN public.extraction_strategies_log esl ON esl.alert_id = a.id
LEFT JOIN public.extracted_content ec ON ec.alert_id = a.id
WHERE esl.extraction_quality IN ('partial', 'failed')
  AND a.created_at >= CURRENT_DATE - INTERVAL '3 days'
ORDER BY a.created_at DESC;

-- ----------------------------------------------------------------------------
-- INSTRU√á√ïES FINAIS
-- ----------------------------------------------------------------------------

/*
ORDEM DE EXECU√á√ÉO:

1. Execute PARTE 1 (criar tabelas)
2. Execute PARTE 2 (deduplica√ß√£o)
3. Execute PARTE 3 (retry inteligente)
4. Execute PARTE 4 (gera√ß√£o de podcast)
5. Execute PARTE 5 (cron job)
6. Execute PARTES 6-8 (views e queries)

COMO USAR:

1. Sistema detecta duplicatas automaticamente
2. Sistema avalia qualidade de extra√ß√£o
3. √Äs 9h UTC, gera roteiro de podcast automaticamente
4. Roteiro fica dispon√≠vel em markdown
5. Exportar para NotebookLM ou outra ferramenta

MONITORAMENTO:

SELECT * FROM podcast_daily_stats;
SELECT * FROM podcast_ready_articles LIMIT 10;
SELECT * FROM duplicate_alerts_summary;
SELECT * FROM problematic_extractions;

GERAR PODCAST MANUALMENTE:

SELECT public.generate_daily_podcast_script(CURRENT_DATE);
*/